{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow_datasets as tfdb\r\n",
    "\r\n",
    "imdb_plaintext, info_plaintext = tfdb.load(\"imdb_reviews\", with_info=True, as_supervised=True)\r\n",
    "imdb_subword, info_subword = tfdb.load(\"imdb_reviews/subwords8k\", with_info=True, as_supervised=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "info_plaintext.features "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for example in imdb_plaintext['train'].take(2):\r\n",
    "    print(example[0].numpy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "info_subword.features\r\n",
    "for example in imdb_subword['train'].take(2):\r\n",
    "    print(example)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tokenizer_subword = info_subword.features['text'].encoder\r\n",
    "\r\n",
    "for example in imdb_subword['train'].take(2):\r\n",
    "    print(tokenizer_subword.decode(example[0]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_data = imdb_plaintext['train']\r\n",
    "\r\n",
    "training_seq = []\r\n",
    "\r\n",
    "for s,_ in train_data:\r\n",
    "    training_seq.append(s.numpy().decode('utf8'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(training_seq)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
    "\r\n",
    "vocab_size =10000\r\n",
    "oov_tok = \"<OOV>\"\r\n",
    "\r\n",
    "tokenizer_context = Tokenizer(num_words= 10000, oov_token = oov_tok)\r\n",
    "tokenizer_context.fit_on_texts(training_seq)\r\n",
    "sequences = tokenizer_context.texts_to_sequences(training_seq) \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tokenizer_context.sequences_to_texts(sequences[0:1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "token_string = tokenizer_subword.encode(training_seq[0])\r\n",
    "print(token_string)\r\n",
    "\r\n",
    "original_string = tokenizer_subword.decode(token_string)\r\n",
    "\r\n",
    "print(original_string)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sample_string = 'This is just a sample.'\r\n",
    "\r\n",
    "tokenized_string = tokenizer_context.texts_to_sequences([sample_string])\r\n",
    "print ('Tokenized string is {}'.format(tokenized_string))\r\n",
    "\r\n",
    "original_string = tokenizer_context.sequences_to_texts(tokenized_string)\r\n",
    "print ('The original string: {}'.format(original_string))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tokenized_string = tokenizer_subword.encode(sample_string)\r\n",
    "print ('Tokenized string is {}'.format(tokenized_string))\r\n",
    "\r\n",
    "original_string = tokenizer_subword.decode(tokenized_string)\r\n",
    "print ('The original string: {}'.format(original_string))\r\n",
    "\r\n",
    "for ts in tokenized_string:\r\n",
    "  print ('{} ----> {}'.format(ts, tokenizer_subword.decode([ts])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "BUFFER_SIZE = 10000\r\n",
    "BATCH_SIZE = 128\r\n",
    "\r\n",
    "train_data, test_data = imdb_subword['train'], imdb_subword['test'], \r\n",
    "\r\n",
    "train_dataset = train_data.shuffle(BUFFER_SIZE)\r\n",
    "\r\n",
    "train_dataset = train_dataset.padded_batch(BATCH_SIZE)\r\n",
    "test_dataset = test_data.padded_batch(BATCH_SIZE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf\r\n",
    "embedding_dim = 64\r\n",
    "\r\n",
    "\r\n",
    "model = tf.keras.Sequential([\r\n",
    "    tf.keras.layers.Embedding(tokenizer_subword.vocab_size, embedding_dim),\r\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\r\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\r\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\r\n",
    "])\r\n",
    "\r\n",
    "model.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "num_epochs = 15\r\n",
    "\r\n",
    "# Set the training parameters\r\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\r\n",
    "\r\n",
    "# Start training\r\n",
    "history = model.fit(train_dataset, epochs=num_epochs, validation_data=test_dataset)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "def plot_graphs(history, string):\r\n",
    "  plt.plot(history.history[string])\r\n",
    "  plt.plot(history.history['val_'+string])\r\n",
    "  plt.xlabel(\"Epochs\")\r\n",
    "  plt.ylabel(string)\r\n",
    "  plt.legend([string, 'val_'+string])\r\n",
    "  plt.show()\r\n",
    "\r\n",
    "plot_graphs(history, \"accuracy\")\r\n",
    "plot_graphs(history, \"loss\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "embedding_layer = model.layers[0]\r\n",
    "\r\n",
    "embedding_weights = embedding_layer.get_weights()[0]\r\n",
    "print(embedding_weights.shape) \r\n",
    "reverse_word_index = tokenizer_context.index_word\r\n",
    "print(reverse_word_index)\r\n",
    "\r\n",
    "# import io\r\n",
    "\r\n",
    "# out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\r\n",
    "# out_m = io.open('meta.tsv', 'w', encoding='utf-8')\r\n",
    "\r\n",
    "# for word_num in range(1, vocab_size):\r\n",
    "\r\n",
    "#   if(word_num<8085):\r\n",
    "#     word_name = reverse_word_index[word_num]\r\n",
    "#     word_embedding = embedding_weights[word_num]\r\n",
    "#     out_m.write(word_name + \"\\n\")\r\n",
    "#     out_v.write('\\t'.join([str(x) for x in word_embedding]) + \"\\n\")\r\n",
    "  \r\n",
    "#   else:\r\n",
    "#     break\r\n",
    "\r\n",
    "# out_v.close()\r\n",
    "# out_m.close()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "user_input = input(\"Enter a movie review: \")\r\n",
    "\r\n",
    "# Preprocess user input\r\n",
    "user_input_encoded = tokenizer_subword.encode(user_input)\r\n",
    "# Predict sentiment\r\n",
    "predicted_prob = model.predict([user_input_encoded])\r\n",
    "# Interpret the prediction\r\n",
    "if predicted_prob >= 0.5:\r\n",
    "    sentiment = 'positive'\r\n",
    "else:\r\n",
    "    sentiment = 'negative'\r\n",
    "\r\n",
    "print(f'The sentiment of the movie review is {sentiment} (Probability: {predicted_prob[0][0]:.4f})')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "The sentiment of the movie review is positive (Probability: 1.0000)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.10.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.10.6 64-bit"
  },
  "interpreter": {
   "hash": "4ce0e62306dd6a5716965d4519ada776f947e6dfc145b604b11307c10277ef29"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}